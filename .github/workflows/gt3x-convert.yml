name: Convert GT3X to CSV

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends unzip curl

      # Validate & sanitize the URL secret without printing it
      - name: Validate GT3X_URL secret (no value leak)
        if: ${{ github.event_name != 'pull_request' || !github.event.pull_request.head.repo.fork }}
        run: |
          if [ -z "${GT3X_URL:-}" ]; then
            echo "❌ GT3X_URL secret is empty or not set."
            exit 1
          fi
          CLEAN_URL="$(printf "%s" "$GT3X_URL" | tr -d '\r\n' | sed 's/^"//; s/"$//; s/^'\''//; s/'\''$//')"
          case "$CLEAN_URL" in
            http://*|https://*) ;;
            *) echo "❌ GT3X_URL must start with http:// or https://"; exit 1 ;;
          esac
          echo "CLEAN_URL=$CLEAN_URL" >> "$GITHUB_ENV"
        env:
          GT3X_URL: ${{ secrets.GT3X_URL }}

      # Skip download on PRs from forks (no secrets available)
      - name: Download GT3X test data
        if: ${{ github.event_name != 'pull_request' || !github.event.pull_request.head.repo.fork }}
        env:
          GT3X_SHA: ${{ secrets.GT3X_SHA }}
        run: |
          mkdir -p data
          curl --fail --location --retry 3 --retry-delay 2 "$CLEAN_URL" -o data/Pecora3.gt3x
          echo "$GT3X_SHA  data/Pecora3.gt3x" | sha256sum -c -

      - name: List data dir
        run: ls -l data || true

      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: Install R packages (CRAN)
        run: |
          Rscript -e 'repos <- c(CRAN="https://cloud.r-project.org"); install.packages("read.gt3x", repos = repos, Ncpus = parallel::detectCores())'

      - name: Run converter (inline R)
        env:
          DATA_DIR: ${{ github.workspace }}/data
        run: |
          set -euo pipefail
          mkdir -p "$DATA_DIR"
          export JOBS="$(nproc || echo 1)"
          echo "Using $JOBS parallel jobs"

          Rscript - <<'RSCRIPT'
          jobs <- as.integer(Sys.getenv("JOBS", "1")); if (is.na(jobs) || jobs < 1) jobs <- 1
          options(mc.cores = jobs)
          if (requireNamespace("data.table", quietly = TRUE)) try(data.table::setDTthreads(jobs), silent = TRUE)

          out_dir <- Sys.getenv("DATA_DIR", unset = "data")
          in_dir  <- out_dir
          if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)

          files <- list.files(in_dir, pattern = "\\.gt3x(\\.gz)?$", full.names = TRUE, ignore.case = TRUE)
          if (length(files) == 0L) { message("No .gt3x files found in ", in_dir); quit(status = 0) }

          if (!requireNamespace("read.gt3x", quietly = TRUE)) install.packages("read.gt3x", repos = "https://cloud.r-project.org")

          for (f in files) {
            bn <- tools::file_path_sans_ext(basename(f))
            bn <- sub("\\.gt3x$", "", bn, ignore.case = TRUE)
            out_csv <- file.path(out_dir, paste0(bn, ".csv"))
            message("Converting: ", f, " -> ", out_csv)
            dat <- read.gt3x::read.gt3x(f, asDataFrame = TRUE)
            utils::write.csv(dat, out_csv, row.names = FALSE)
          }
          RSCRIPT

          echo "--- data directory after conversion ---"
          ls -lh "$DATA_DIR" || true

      - name: Upload converted CSVs (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: converted-csvs
          path: data/*.csv
          if-no-files-found: warn
