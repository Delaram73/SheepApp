name: Convert GT3X to CSV

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: Check out repo (with LFS)
        uses: actions/checkout@v4
        with:
          lfs: true           # fetch real LFS content, not pointers
          fetch-depth: 0
      - name: Download GT3X test data
        run: |
          mkdir -p data
          curl -fL "$GT3X_URL" -o data/Pecora3.gt3x
          echo "$GT3X_SHA  data/Pecora3.gt3x" | sha256sum -c -
        env:
          GT3X_URL: ${{ secrets.GT3X_URL }}
          GT3X_SHA: ${{ secrets.GT3X_SHA }}

      - name: Verify & pull GT3X via LFS
        shell: bash
        run: |
          set -euo pipefail

          echo "== Git LFS info =="
          git lfs version || true
          git lfs env || true

          echo "== List LFS files =="
          git lfs ls-files -l || true

          echo "== Check data directory =="
          ls -l data || true

          shopt -s nullglob
          found=0
          for f in data/*.gt3x data/*.gt3x.gz; do
            found=1
            echo "--- Inspecting $f ---"
            ls -lh "$f" || true
            file "$f" || true
            echo "First bytes:"
            head -c 100 "$f" | hexdump -C || true
            echo "Pointer check:"
            if head -c 200 "$f" | grep -q 'version https://git-lfs.github.com/spec'; then
              echo "❌ $f is a Git LFS pointer file (not the real binary)."
              echo "Attempting 'git lfs pull' to fetch real content..."
              git lfs pull --include="$f" || true
              # Re-check
              if head -c 200 "$f" | grep -q 'version https://git-lfs.github.com/spec'; then
                echo "❌ Still a pointer after 'git lfs pull'."
                echo "Likely causes:"
                echo "  • LFS bandwidth/storage quota exceeded for the repo/org"
                echo "  • Missing access to LFS for this workflow token"
                echo "  • The file was committed as a pointer but the binary was never uploaded"
                echo "Fix suggestions:"
                echo "  • Ensure LFS quota is available"
                echo "  • Make sure the repo tracks '*.gt3x' in .gitattributes and the real files were pushed"
                echo "  • If this is from a fork/PR, consider moving test data to a public URL or a release asset"
                exit 1
              fi
              echo "✅ Fetched real content for $f"
            fi

            # Final sanity: ensure it's a readable zip (gt3x is a zip container)
            if ! unzip -l "$f" >/dev/null 2>&1; then
              echo "❌ $f is not a readable zip; the file may be corrupted or incomplete."
              exit 1
            fi
          done

          if [[ "$found" -eq 0 ]]; then
            echo "ℹ️ No .gt3x files found under ./data"
          fi

      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends unzip

      - name: Install R packages (CRAN)
        run: |
          Rscript -e 'repos <- c(CRAN="https://cloud.r-project.org"); install.packages("read.gt3x", repos = repos, Ncpus = parallel::detectCores())'

      - name: Run converter (inline R)
        env:
          DATA_DIR: ${{ github.workspace }}/data
        run: |
          set -euo pipefail
          mkdir -p "$DATA_DIR"
          export JOBS="$(nproc || echo 1)"
          echo "Using $JOBS parallel jobs"

          Rscript - <<'RSCRIPT'
          jobs <- as.integer(Sys.getenv("JOBS", "1")); if (is.na(jobs) || jobs < 1) jobs <- 1
          options(mc.cores = jobs)
          if (requireNamespace("data.table", quietly = TRUE)) try(data.table::setDTthreads(jobs), silent = TRUE)

          out_dir <- Sys.getenv("DATA_DIR", unset = "data")
          in_dir  <- out_dir
          if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)

          files <- list.files(in_dir, pattern = "\\.gt3x(\\.gz)?$", full.names = TRUE, ignore.case = TRUE)
          if (length(files) == 0L) { message("No .gt3x files found in ", in_dir); quit(status = 0) }

          if (!requireNamespace("read.gt3x", quietly = TRUE)) install.packages("read.gt3x", repos = "https://cloud.r-project.org")

          for (f in files) {
            bn <- tools::file_path_sans_ext(basename(f))
            bn <- sub("\\.gt3x$", "", bn, ignore.case = TRUE)
            out_csv <- file.path(out_dir, paste0(bn, ".csv"))
            message("Converting: ", f, " -> ", out_csv)
            dat <- read.gt3x::read.gt3x(f, asDataFrame = TRUE)
            utils::write.csv(dat, out_csv, row.names = FALSE)
          }
          RSCRIPT

          echo "--- data directory after conversion ---"
          ls -lh "$DATA_DIR" || true

      - name: Upload converted CSVs (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: converted-csvs
          path: data/*.csv
          if-no-files-found: warn
