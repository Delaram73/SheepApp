name: Upload CSVs to InfluxDB Cloud

on:
  push:
    paths: ["data/**/*.csv"]   # Runs automatically when CSVs under data/ change
  workflow_dispatch:           # Lets you run it manually from the Actions tab

jobs:
  # Optional smoke test you can run manually to verify URL/org/token
  smoketest:
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - name: Install influx CLI
        run: |
          curl -sL https://repos.influxdata.com/influxdata-archive.key | sudo gpg --dearmor -o /usr/share/keyrings/influx-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/influx-archive-keyring.gpg] https://repos.influxdata.com/$(. /etc/os-release && echo $ID) $(. /etc/os-release && echo $VERSION_CODENAME) stable" | sudo tee /etc/apt/sources.list.d/influxdata.list
          sudo apt-get update && sudo apt-get install -y influxdb2-cli
      - name: Write one test point
        env:
          INFLUX_URL:    ${{ secrets.INFLUX_URL }}
          INFLUX_ORG:    ${{ secrets.INFLUX_ORG }}
          INFLUX_BUCKET: ${{ secrets.INFLUX_BUCKET }}
          INFLUX_TOKEN:  ${{ secrets.INFLUX_TOKEN }}
        run: |
          influx write \
            --url "$INFLUX_URL" --org "$INFLUX_ORG" --bucket "$INFLUX_BUCKET" --token "$INFLUX_TOKEN" \
            --record 'behavior_pred,sheep_id=smoketest confidence=0.99'
      - name: Query back last 5 minutes
        env:
          INFLUX_URL:    ${{ secrets.INFLUX_URL }}
          INFLUX_ORG:    ${{ secrets.INFLUX_ORG }}
          INFLUX_BUCKET: ${{ secrets.INFLUX_BUCKET }}
          INFLUX_TOKEN:  ${{ secrets.INFLUX_TOKEN }}
        run: |
          influx query --url "$INFLUX_URL" --org "$INFLUX_ORG" --token "$INFLUX_TOKEN" '
            from(bucket: "'$INFLUX_BUCKET'")
              |> range(start: -5m)
              |> filter(fn: (r) => r._measurement == "behavior_pred" and r.sheep_id == "smoketest")
              |> limit(n: 1)
          '

  # Main job: upload CSV files under data/
  upload-csvs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install influx CLI
        run: |
          curl -sL https://repos.influxdata.com/influxdata-archive.key | sudo gpg --dearmor -o /usr/share/keyrings/influx-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/influx-archive-keyring.gpg] https://repos.influxdata.com/$(. /etc/os-release && echo $ID) $(. /etc/os-release && echo $VERSION_CODENAME) stable" | sudo tee /etc/apt/sources.list.d/influxdata.list
          sudo apt-get update && sudo apt-get install -y influxdb2-cli

      - name: Write CSV files to InfluxDB Cloud
        env:
          INFLUX_URL:    ${{ secrets.INFLUX_URL }}
          INFLUX_ORG:    ${{ secrets.INFLUX_ORG }}
          INFLUX_BUCKET: ${{ secrets.INFLUX_BUCKET }}
          INFLUX_TOKEN:  ${{ secrets.INFLUX_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail
          shopt -s globstar nullglob

          files=(data/**/*.csv)
          if [ ${#files[@]} -eq 0 ]; then
            echo "No CSV files found under data/."
            exit 0
          fi

          for f in "${files[@]}"; do
            echo "Writing $f ..."
            case "$f" in
              *pred*.csv|*prediction*.csv|*predictions/*.csv)
                # Predicted output schema: Time, behaviour (string field), confidence (float field), sheep_id (tag)
                influx write \
                  --url "$INFLUX_URL" --org "$INFLUX_ORG" --bucket "$INFLUX_BUCKET" --token "$INFLUX_TOKEN" \
                  --file "$f" --format csv --batch-size 5000 \
                  --header "#constant measurement,behavior_pred" \
                  --header "#datatype dateTime:RFC3339,string,double,tag" \
                  --header "#columns Time,behaviour,confidence,sheep_id"
                ;;
              *)
                # Raw sensor schema: Time, X, Y, Z (float fields); sheep_id (tag)
                influx write \
                  --url "$INFLUX_URL" --org "$INFLUX_ORG" --bucket "$INFLUX_BUCKET" --token "$INFLUX_TOKEN" \
                  --file "$f" --format csv --batch-size 5000 \
                  --header "#constant measurement,behavior_pred" \
                  --header "#datatype dateTime:RFC3339,double,double,double,tag" \
                  --header "#columns Time,X,Y,Z,sheep_id"
                ;;
            esac
          done
